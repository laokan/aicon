# Fast-Whisper / CTranslate2 GPU åŠ é€Ÿé…ç½®è¯´æ˜ï¼ˆLinux/WSLï¼‰

ä¸ºäº†è®© fast-whisper åœ¨ GPU ä¸Šè¿è¡Œï¼Œéœ€ç¡®ä¿ CUDA ç›¸å…³åŠ¨æ€åº“ï¼ˆ`libcublas.so.12`ã€`libcudnn.so` ç­‰ï¼‰èƒ½è¢«è¿è¡Œæ—¶æ­£ç¡®åŠ è½½ã€‚ä½¿ç”¨ pip/uv å®‰è£…çš„ CUDA wheelï¼ˆå¦‚ `nvidia-cublas-cu12`ã€`nvidia-cudnn-cu12`ï¼‰ä¼šå°†åº“æ–‡ä»¶æ”¾åœ¨è™šæ‹Ÿç¯å¢ƒçš„ `site-packages` ä¸­ï¼Œå› æ­¤éœ€è¦æ‰‹åŠ¨å°†å…¶åŠ å…¥ `LD_LIBRARY_PATH`ã€‚

## 1. æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ

```bash
source .venv/bin/activate
```

## 2. è®¾ç½® CUDA åŠ¨æ€åº“è·¯å¾„

```bash
export LD_LIBRARY_PATH="<PROJECT_PATH>/.venv/lib/python3.12/site-packages/nvidia/cublas/lib:<PROJECT_PATH>/.venv/lib/python3.12/site-packages/nvidia/cudnn/lib:$LD_LIBRARY_PATH"
```

ï¼ˆå°† `<PROJECT_PATH>` æ›¿æ¢ä¸ºå®é™…å·¥ç¨‹æ ¹ç›®å½•ï¼‰

## 3. è‡ªåŠ¨åŠ è½½ï¼ˆå¯é€‰ï¼‰

å°†ä¸‹é¢å†…å®¹è¿½åŠ åˆ° `.venv/bin/activate`ï¼Œä¹‹åæ¯æ¬¡æ¿€æ´» venv å°†è‡ªåŠ¨å¯ç”¨ GPU ä¾èµ–åº“ï¼š

```bash
export LD_LIBRARY_PATH="<PROJECT_PATH>/.venv/lib/python3.12/site-packages/nvidia/cublas/lib:<PROJECT_PATH>/.venv/lib/python3.12/site-packages/nvidia/cudnn/lib:$LD_LIBRARY_PATH"
```

## 4. ä¿®æ”¹ä»£ç 

`backend\src\services\faster_whisper_service.py`
``` python
class WhisperTranscriptionService:
    def __init__(self, model_size="small", device="cuda", compute_type="float32"):
        """
        åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«æœåŠ¡ï¼ˆå¯å¤ç”¨æ¨¡å‹ï¼Œä¸éœ€è¦æ¯æ¬¡éƒ½åŠ è½½ï¼‰
        """
        logger.info(f"ğŸ”„ æ­£åœ¨åŠ è½½ Whisper æ¨¡å‹: {model_size} ...")
        self.model = WhisperModel(model_size, device=device, compute_type=compute_type)
        self.cc = OpenCC("t2s")  # ç¹â†’ç®€è½¬æ¢
        logger.info(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
```

å°† `device` ä¿®æ”¹ä¸ºcudaï¼Œ`model_size`ä¹Ÿå¯ä»¥ä¿®æ”¹ä¸ºé€‚åˆä½ æ˜¾å¡çš„å°ºå¯¸ã€‚